{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiplicacion de matrices secuencial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución secuencial: 1.4329 segundos\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import random\n",
    "import time\n",
    "from typing import List\n",
    "import numpy as np\n",
    "\n",
    "def generar_matriz(filas: int, columnas: int) -> List[List[int]]:\n",
    "    return [[random.randint(1, 10) for _ in range(columnas)] for _ in range(filas)]\n",
    "\n",
    "def multiplicar_matrices_secuencial(matriz_a: List[List[int]], matriz_b: List[List[int]]) -> List[List[int]]:\n",
    "    filas_a = len(matriz_a)\n",
    "    columnas_a = len(matriz_a[0])\n",
    "    columnas_b = len(matriz_b[0])\n",
    "    \n",
    "    resultado: List[List[int]] = [[0 for _ in range(columnas_b)] for _ in range(filas_a)]\n",
    "    \n",
    "    for i in range(filas_a):\n",
    "        for j in range(columnas_b):\n",
    "            for k in range(columnas_a):\n",
    "                resultado[i][j] += matriz_a[i][k] * matriz_b[k][j]\n",
    "                \n",
    "    return resultado\n",
    "\n",
    "dimension: int = 250\n",
    "matriz_a = generar_matriz(dimension, dimension)\n",
    "matriz_b = generar_matriz(dimension, dimension)\n",
    "\n",
    "# Multiplicación secuencial\n",
    "inicio = time.time()\n",
    "resultado_secuencial = multiplicar_matrices_secuencial(matriz_a, matriz_b)\n",
    "fin = time.time()\n",
    "tiempo_secuencial = fin - inicio\n",
    "print(f\"Tiempo de ejecución secuencial: {tiempo_secuencial:.4f} segundos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiplicacion de matrices con multiprocesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución paralelo (8 cores): 0.3416 segundos\n",
      "Speedup: 4.20x\n"
     ]
    }
   ],
   "source": [
    "def multiplicar_fila(args: tuple) -> List[int]:\n",
    "    fila_a, matriz_b, j = args\n",
    "    resultado: List[int] = []\n",
    "    for j in range(len(matriz_b[0])):\n",
    "        suma = 0\n",
    "        for k in range(len(matriz_b)):\n",
    "            suma += fila_a[k] * matriz_b[k][j]\n",
    "        resultado.append(suma)\n",
    "    return resultado\n",
    "\n",
    "def multiplicar_matrices_paralelo(matriz_a: List[List[int]], matriz_b: List[List[int]], num_procesos: int) -> List[List[int]]:\n",
    "    \n",
    "    with multiprocessing.Pool(processes=num_procesos) as pool:\n",
    "        args: List[tuple] = [(fila_a, matriz_b, j) for j, fila_a in enumerate(matriz_a)]\n",
    "        resultado: List[List[int]] = pool.map(multiplicar_fila, args)\n",
    "    \n",
    "    return resultado\n",
    "\n",
    "dimension = 250\n",
    "matriz_a = generar_matriz(dimension, dimension)\n",
    "matriz_b = generar_matriz(dimension, dimension)\n",
    "    \n",
    "num_procesos = multiprocessing.cpu_count()\n",
    "inicio = time.time()\n",
    "resultado_paralelo = multiplicar_matrices_paralelo(matriz_a, matriz_b, num_procesos)\n",
    "fin = time.time()\n",
    "tiempo_paralelo = fin - inicio\n",
    "print(f\"Tiempo de ejecución paralelo ({num_procesos} cores): {tiempo_paralelo:.4f} segundos\")    \n",
    "print(f\"Speedup: {tiempo_secuencial/tiempo_paralelo:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiplicación de matrices con numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución con NumPy: 0.0291 segundos\n",
      "Speedup (NumPy): 49.31x\n"
     ]
    }
   ],
   "source": [
    "dimension = 250\n",
    "matriz_a = generar_matriz(dimension, dimension)\n",
    "matriz_b = generar_matriz(dimension, dimension)\n",
    "\n",
    "inicio = time.time()\n",
    "resultado_numpy = np.dot(matriz_a, matriz_b)\n",
    "fin = time.time()\n",
    "tiempo_numpy = fin - inicio\n",
    "print(f\"Tiempo de ejecución con NumPy: {tiempo_numpy:.4f} segundos\")\n",
    "print(f\"Speedup (NumPy): {tiempo_secuencial/tiempo_numpy:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiplicación de matrices con torch CPU y CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución con PyTorch (CPU): 0.0003 segundos\n",
      "Speedup (PyTorch CPU): 4202.77x\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "dimension = 250\n",
    "matriz_a = generar_matriz(dimension, dimension)\n",
    "matriz_b = generar_matriz(dimension, dimension)\n",
    "\n",
    "a = torch.tensor(matriz_a, dtype=torch.float32)\n",
    "b = torch.tensor(matriz_b, dtype=torch.float32)\n",
    "\n",
    "#warmup \n",
    "_ = torch.matmul(a, b)\n",
    "\n",
    "\n",
    "inicio = time.time()\n",
    "resultado_torch_cpu = torch.matmul(a, b)\n",
    "fin = time.time()\n",
    "tiempo_torch_cpu = fin - inicio\n",
    "print(f\"Tiempo de ejecución con PyTorch (CPU): {tiempo_torch_cpu:.4f} segundos\")\n",
    "print(f\"Speedup (PyTorch CPU): {tiempo_secuencial/tiempo_torch_cpu:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiempo de ejecución con PyTorch (GPU): 1.9788742065429688e-05 segundos\n",
      "Speedup (PyTorch GPU): 72409.08x\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"No se encontraron GPUs disponibles\")\n",
    "\n",
    "else:    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    dimension = 250\n",
    "    matriz_a = generar_matriz(dimension, dimension)\n",
    "    matriz_b = generar_matriz(dimension, dimension)\n",
    "\n",
    "    a = torch.tensor(matriz_a, dtype=torch.float32)\n",
    "    b = torch.tensor(matriz_b, dtype=torch.float32)\n",
    "\n",
    "    a = a.to(device)\n",
    "    b = b.to(device)\n",
    "\n",
    "    #warmup \n",
    "    _ = torch.matmul(a, b)\n",
    "\n",
    "    inicio = time.time()\n",
    "    resultado_torch_cpu = torch.matmul(a, b)\n",
    "    fin = time.time()\n",
    "    tiempo_torch_cpu = fin - inicio\n",
    "    print(f\"Tiempo de ejecución con PyTorch (GPU): {tiempo_torch_cpu} segundos\")\n",
    "    print(f\"Speedup (PyTorch GPU): {tiempo_secuencial/tiempo_torch_cpu:.2f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
